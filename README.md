# KFC Voice Agent

## ğŸ“ Project Structure

```
voice_agent_poc/
â”œâ”€â”€ main.py                         # Entry point - orchestrates the flow
â”œâ”€â”€ logger.py                       # Rotating datetime-based logger setup
â”œâ”€â”€ ai/                             # AI service classes (loaded into memory once)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ stt.py                      # Speech-to-Text class (Speechmatics)
â”‚   â”œâ”€â”€ llm.py                      # LLM class (Google Gemini)
â”‚   â””â”€â”€ tts.py                      # Text-to-Speech class
â”œâ”€â”€ orchestrator/                   # Business logic - one file per conversation step
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ greeting.py                 # Greeting + intent detection (yes/no/others, 1 retry)
â”‚   â”œâ”€â”€ order_item.py               # Order item collection
â”‚   â”œâ”€â”€ quantity.py                 # Quantity collection
â”‚   â”œâ”€â”€ extras.py                   # Extras collection
â”‚   â””â”€â”€ address.py                  # Address collection + LLM reformatting
â”œâ”€â”€ integration/                    # External service integrations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ routeToAgent.py             # Route call to human agent (stub)
â”œâ”€â”€ logs/                           # Auto-created, one log file per execution
â”‚   â””â”€â”€ 2026-02-13_14-30-00.log
â”œâ”€â”€ .env                            # API keys (not committed)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ—ï¸ Architecture Principles

### 1. Separation of Concerns

- **`ai/`** = Technical implementations only (how to transcribe, how to call LLM, how to speak)
- **`orchestrator/`** = Business logic only (what to ask, when, retry logic, decisions)
- **`integration/`** = External service connections (routing, CRM, etc.)
- **`logger.py`** = Logging setup, one timestamped file per execution

### 2. Single Responsibility

Each class and method has ONE clear job:

- `STT.transcribe()` â†’ Listens to mic, returns transcribed text
- `LLM.get_response(prompt)` â†’ Sends prompt to Gemini, returns response
- `TTS.play_audio(text)` â†’ Plays audio to caller
- Each orchestrator â†’ Handles ONE step of the conversation flow

### 3. AI Classes Loaded Once into Memory

All three AI classes are instantiated once in `main.py` and injected into every orchestrator. This means no repeated initialisation on every call.

```python
# main.py - instantiated once
stt = STT(logger=logger)
llm = LLM(logger=logger)
tts = TTS(logger=logger)

# Injected into each orchestrator
greeting = GreetingOrchestrator(logger=logger)  # internally uses same pattern
```

### 4. Easy to Swap AI Services

Want to switch from Speechmatics to Google STT? Only change `ai/stt.py` â€” keep `transcribe()` signature the same.
Want to switch from Gemini to GPT-4 or Claude? Only change `ai/llm.py` â€” keep `get_response(prompt)` signature the same.

Orchestrators never need to change when switching providers.

---

## ğŸ¯ Conversation Flow

```
main.py
  â†“ (1 second delay)
GreetingOrchestrator
  â”œâ”€â†’ TTS: "Assalam o Alaikum, thank you for calling KFC..."
  â”œâ”€â†’ STT: transcribe()
  â”œâ”€â†’ Intent: keyword match â†’ LLM fallback
  â”œâ”€â†’ yes  â†’ proceed
  â”œâ”€â†’ no   â†’ RouteToAgent â†’ exit
  â””â”€â†’ others â†’ retry once â†’ RouteToAgent â†’ exit
       â†“ (if yes)
OrderItemOrchestrator
  â”œâ”€â†’ TTS: "Aap kya order karna chahte hain?"
  â””â”€â†’ STT: transcribe()
       â†“
QuantityOrchestrator
  â”œâ”€â†’ TTS: "Quantity bataein"
  â””â”€â†’ STT: transcribe()
       â†“
ExtrasOrchestrator
  â”œâ”€â†’ TTS: "Kya kuch aur chahiye?"
  â””â”€â†’ STT: transcribe()
       â†“
AddressOrchestrator
  â”œâ”€â†’ TTS: "Apna address bataen?"
  â”œâ”€â†’ STT: transcribe()
  â”œâ”€â†’ LLM: reformat Urdu address to English
  â””â”€â†’ Invalid â†’ retry once â†’ abort
       â†“
Order Summary printed to terminal
```

---

## ğŸ“ Greeting Orchestrator Details

Intent detection uses a **hybrid approach**:

1. **Keyword matching first** (fast, no LLM cost)
   - No keywords checked before yes keywords to avoid false positives
2. **LLM fallback** if no keyword matched

Intent outcomes:
- `yes` â†’ Proceed to order flow
- `no` â†’ Play farewell, call `RouteToAgent.routeCallToAgent()`, exit
- `others` â†’ Retry greeting once â†’ if still `others` â†’ same as `no`

---

## ğŸ“‹ Logging

Every execution creates a new log file in `logs/` with a datetime-stamped filename:

```
logs/
â””â”€â”€ 2026-02-13_14-30-00.log
```

**Log file captures:** STT partials, STT finals, LLM prompts, LLM responses, intent decisions, keyword matches, errors and warnings.

**Terminal only shows:** the conversation flow â€” TTS output, user responses, intent results, order summary.

---

## ğŸš€ Setup

1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Configure environment â€” create a `.env` file:**
   ```
   SPEECHMATICS_API_KEY=your_key_here
   GEMINI_DEVELOPER_API_KEY=your_key_here
   ```

3. **Run the agent:**
   ```bash
   python main.py
   ```

---

## ğŸ“Š Context Dictionary

The `context` dictionary is built up across orchestrators and contains the full order at the end:

```python
{
    "order_item": "Zinger Burger",
    "quantity": "2",
    "extra": "Fries",
    "address": "House Number 5, B Block, DHA Phase 2, Lahore"
}
```

---

## ğŸ”§ Extending the System

### Adding a new conversation step:

1. Create `orchestrator/new_step.py`
2. Define class with `__init__(self, logger=None)` and `execute(self, context)` method
3. Use `self.stt.transcribe()`, `self.llm.get_response()`, `self.tts.play_audio()`
4. Add to the flow in `main.py`

### Adding a new integration:

1. Create `integration/new_service.py`
2. Define class with required methods
3. Import and call from relevant orchestrator

---

## ğŸ¯ Key Improvements from Sprint 1 â†’ Sprint 2

| | Sprint 1 | Sprint 2 |
|---|---|---|
| AI files location | root directory | `ai/` folder |
| AI services | standalone functions | classes loaded into memory |
| Intent detection | LLM only | keyword match + LLM fallback |
| Logging | print statements only | rotating datetime log files |
| Human handoff | not implemented | `integration/routeToAgent.py` stub |
| Startup delay | none | 1 second delay in `main.py` |