# Voice Agent POC

## ğŸ“ Project Structure

```
voice_agent_poc/
â”œâ”€â”€ main.py                         # Entry point - orchestrates the flow
â”œâ”€â”€ logger.py                       # Rotating datetime-based logger setup
â”œâ”€â”€ ai/                             # AI service classes (loaded into memory once)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ stt.py                      # Speech-to-Text class (Speechmatics)
â”‚   â”œâ”€â”€ llm.py                      # LLM class (Google Gemini)
â”‚   â””â”€â”€ tts.py                      # Text-to-Speech class
â”œâ”€â”€ orchestrator/                   # Business logic - one file per conversation step
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ greeting.py                 # Greeting + intent detection (yes/no/others, 1 retry)
â”‚   â”œâ”€â”€ order_item.py               # Order item collection
â”‚   â”œâ”€â”€ quantity.py                 # Quantity collection
â”‚   â”œâ”€â”€ extras.py                   # Extras collection
â”‚   â””â”€â”€ address.py                  # Customer profile fetch + address confirmation
â”œâ”€â”€ integration/                    # External service integrations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ routeToAgent.py             # Route call to human agent
â”‚   â””â”€â”€ CustomerProfile.py          # Customer profile lookup + location check
â”œâ”€â”€ logs/                           # Auto-created, one log file per execution
â”‚   â””â”€â”€ 2026-02-13_14-30-00.log
â”œâ”€â”€ .env                            # API keys (not committed)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ—ï¸ Architecture Principles

### 1. Separation of Concerns

- **`ai/`** = Technical implementations only (how to transcribe, how to call LLM, how to speak)
- **`orchestrator/`** = Business logic only (what to ask, when, retry logic, decisions)
- **`integration/`** = External service connections (customer profile, routing, location checks)
- **`logger.py`** = Logging setup, one timestamped file per execution

### 2. Single Responsibility

Each class and method has ONE clear job:

- `STT.transcribe()` â†’ Listens to mic, returns transcribed text
- `LLM.get_response(prompt)` â†’ Sends prompt to Gemini, returns response
- `TTS.play_audio(text)` â†’ Plays audio to caller
- `CustomerProfile.getCustomerProfile(msisdn)` â†’ Fetches customer details
- Each orchestrator â†’ Handles ONE step of the conversation flow

### 3. AI Classes Loaded Once into Memory

All three AI classes are instantiated once in `main.py` and injected into every orchestrator. This means no repeated initialisation on every call.

```python
# main.py - instantiated once per orchestrator
greeting = GreetingOrchestrator(logger=logger)
address = AddressOrchestrator(logger=logger)
# Each orchestrator internally creates: STT(logger), LLM(logger), TTS(logger)
```

### 4. Easy to Swap AI Services

Want to switch from Speechmatics to Google STT? Only change `ai/stt.py` â€” keep `transcribe()` signature the same.
Want to switch from Gemini to GPT-4 or Claude? Only change `ai/llm.py` â€” keep `get_response(prompt)` signature the same.

Orchestrators never need to change when switching providers.

---

## ğŸ¯ Conversation Flow

```
main.py
  â†“ (1 second delay)
  â†“ (Initialize context with msisdn)
  â†“
GreetingOrchestrator
  â”œâ”€â†’ TTS: "Assalam o Alaikum, thank you for calling KFC..."
  â”œâ”€â†’ STT: transcribe()
  â”œâ”€â†’ Intent: keyword match â†’ LLM fallback
  â”œâ”€â†’ yes  â†’ save intent="order" â†’ proceed
  â”œâ”€â†’ no   â†’ RouteToAgent â†’ exit
  â””â”€â†’ others â†’ retry once â†’ RouteToAgent â†’ exit
       â†“ (if yes)
OrderItemOrchestrator
  â”œâ”€â†’ TTS: "Aap kya order karna chahte hain?"
  â””â”€â†’ STT: transcribe() â†’ save to context
       â†“
QuantityOrchestrator
  â”œâ”€â†’ TTS: "Quantity bataein"
  â””â”€â†’ STT: transcribe() â†’ save to context
       â†“
ExtrasOrchestrator
  â”œâ”€â†’ TTS: "Kya kuch aur chahiye?"
  â””â”€â†’ STT: transcribe() â†’ save to context
       â†“
AddressOrchestrator
  â”œâ”€â†’ CustomerProfile.getCustomerProfile(msisdn)
  â”‚     â””â”€â†’ returns { customer_name, customer_address, ... }
  â”‚         â””â”€â†’ saved to context["customer_profile"]
  â”‚
  â”œâ”€â†’ TTS: "Meri baat {name} se ho rahi hai. Aap ka address {address} hai..."
  â”œâ”€â†’ STT: transcribe()
  â”œâ”€â†’ LLM: check address confirmation intent (yes/no/others)
  â”‚
  â”œâ”€â†’ yes   â†’ TTS: "Shukria, Kindly wait karien"
  â”‚           â””â”€â†’ CustomerProfile.checkAvailableLocation() â†’ exit()
  â”‚
  â”œâ”€â†’ no    â†’ RouteToAgent â†’ exit
  â”‚
  â””â”€â†’ others â†’ TTS: "Sorry..." + address_question
              â”œâ”€â†’ STT: transcribe()
              â”œâ”€â†’ LLM: check intent again
              â”œâ”€â†’ yes    â†’ TTS: "Shukria..." â†’ checkAvailableLocation() â†’ exit()
              â””â”€â†’ no/others â†’ RouteToAgent â†’ exit
       â†“
Order Summary printed to terminal
```

---

## ğŸ“ Key Orchestrator Details

### Greeting Orchestrator
Intent detection uses a **hybrid approach**:
1. **Keyword matching first** (fast, no LLM cost)
   - No keywords checked before yes keywords to avoid false positives
2. **LLM fallback** if no keyword matched

Intent outcomes:
- `yes` â†’ Save `context["intent"] = "order"` â†’ Proceed to order flow
- `no` â†’ Play farewell, call `RouteToAgent.routeCallToAgent()`, exit
- `others` â†’ Retry greeting once â†’ if still `others` â†’ same as `no`

### Address Orchestrator
1. **Fetches customer profile** using `context["msisdn"]`
2. **Confirms address** with personalized message using customer name and stored address
3. **Validates response** (yes/no/others) via LLM
4. **On yes**: Says thank you, calls `checkAvailableLocation()`, exits
5. **On no**: Routes to agent
6. **On others**: Retries once with apology, then routes to agent if still unclear

---

## ğŸ“Š Context Dictionary

The `context` dictionary stores all data for one call session:

```python
{
    "msisdn": "923001234567",
    "intent": "order",
    "customer_profile": {
        "customerId": 101,
        "customer_name": "John Doe",
        "phone1": "923001234567",
        "customer_address": "G-8, Islamabad"
    },
    "order_item": "Zinger Burger",
    "quantity": "2",
    "extra": "Fries",
    "address": "G-8, Islamabad",
    "cost": None
}
```

---

## ğŸ“‹ Logging

Every execution creates a new log file in `logs/` with a datetime-stamped filename:

```
logs/
â””â”€â”€ 2026-02-13_14-30-00.log
```

**Log file captures:** STT partials, STT finals, LLM prompts, LLM responses, intent decisions, keyword matches, customer profile fetch, errors and warnings.

**Terminal only shows:** the conversation flow â€” TTS output, user responses, intent results, customer profile fetch, order summary.

---

## ğŸš€ Setup

1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Configure environment â€” create a `.env` file:**
   ```
   SPEECHMATICS_API_KEY=your_key_here
   GEMINI_DEVELOPER_API_KEY=your_key_here
   ```

3. **Run the agent:**
   ```bash
   python main.py
   ```

---

## ğŸ”§ Extending the System

### Adding a new conversation step:

1. Create `orchestrator/new_step.py`
2. Define class with `__init__(self, logger=None)` and `execute(self, context)` method
3. Instantiate AI services: `self.stt = STT(logger=logger)`, etc.
4. Use `self.stt.transcribe()`, `self.llm.get_response()`, `self.tts.play_audio()`
5. Add to the flow in `main.py`

### Adding a new integration:

1. Create `integration/new_service.py`
2. Define class with required methods
3. Import and instantiate in relevant orchestrator
4. Call methods as needed

---

## ğŸ¯ Sprint Evolution

| Feature | Sprint 1 | Sprint 2 | Sprint 3 |
|---------|----------|----------|----------|
| **AI files** | root directory | `ai/` folder (classes) | âœ… |
| **Intent detection** | LLM only | keyword + LLM fallback | âœ… |
| **Logging** | print only | datetime log files | âœ… |
| **Customer profile** | âŒ | âŒ | âœ… Fetch via msisdn |
| **Address flow** | Simple LLM reformat | Simple LLM reformat | âœ… Profile-based confirmation |
| **Routing** | âŒ | stub | âœ… Called on no/others |
| **Context** | order details only | order details only | âœ… Full session (msisdn, profile, intent) |
| **Startup delay** | âŒ | 1 second | âœ… |

---

## ğŸ“ Integration Points

### CustomerProfile Service

**`getCustomerProfile(msisdn)`**
- Input: Phone number string
- Output: Dict with `customerId`, `customer_name`, `phone1`, `customer_address`
- Currently returns static data â€” replace with real API call

**`checkAvailableLocation(customer_address)`**
- Input: Address string
- Output: None (exits for now)
- Currently stub â€” implement delivery zone validation

### RouteToAgent Service

**`routeCallToAgent(context_str)`**
- Input: Full context as string
- Output: None
- Currently stub â€” implement call transfer logic

---

## ğŸ” Debugging

Check the log file in `logs/` for detailed execution trace including:
- STT partial and final transcriptions
- LLM prompts and responses
- Customer profile API calls
- Intent detection results
- Routing decisions

Terminal output is kept clean showing only the conversation flow.
